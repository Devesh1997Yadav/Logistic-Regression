{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (398, 1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((171, 30), (171, 1))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\ADMIN\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "print('Score :',accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 59,   4],\n",
       "       [  1, 107]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix is')\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        63\n",
      "           1       0.96      0.99      0.98       108\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = LR.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob[:,1], pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc scores\n",
    "auc_score1 = roc_auc_score(y_test, pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x173464de978>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr1, tpr1, linestyle='--',color='green', label='Logistic Regression')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model with standar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = scalar.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = pd.DataFrame(X1,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>-0.312589</td>\n",
       "      <td>-0.931027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>-0.217664</td>\n",
       "      <td>-1.058611</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>-0.809117</td>\n",
       "      <td>-0.895587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>2.137194</td>\n",
       "      <td>1.043695</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>-0.820070</td>\n",
       "      <td>-0.561032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0       1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
       "1       1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
       "2       1.579888      0.456187        1.566503   1.558884         0.942210   \n",
       "3      -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
       "4       1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     2.110995      0.721473        2.060786   2.343856         1.041842   \n",
       "565     1.704854      2.085134        1.615931   1.723842         0.102458   \n",
       "566     0.702284      2.045574        0.672676   0.577953        -0.840484   \n",
       "567     1.838341      2.336457        1.982524   1.735218         1.525767   \n",
       "568    -1.808401      1.221792       -1.814389  -1.347789        -3.112085   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            3.283515        2.652874             2.532475       2.217515   \n",
       "1           -0.487072       -0.023846             0.548144       0.001392   \n",
       "2            1.052926        1.363478             2.037231       0.939685   \n",
       "3            3.402909        1.915897             1.451707       2.867383   \n",
       "4            0.539340        1.371011             1.428493      -0.009560   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.219060        1.947285             2.320965      -0.312589   \n",
       "565         -0.017833        0.693043             1.263669      -0.217664   \n",
       "566         -0.038680        0.046588             0.105777      -0.809117   \n",
       "567          3.272144        3.296944             2.658866       2.137194   \n",
       "568         -1.150752       -1.114873            -1.261820      -0.820070   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                  2.255747  ...      1.886690      -1.359293   \n",
       "1                 -0.868652  ...      1.805927      -0.369203   \n",
       "2                 -0.398008  ...      1.511870      -0.023974   \n",
       "3                  4.910919  ...     -0.281464       0.133984   \n",
       "4                 -0.562450  ...      1.298575      -1.466770   \n",
       "..                      ...  ...           ...            ...   \n",
       "564               -0.931027  ...      1.901185       0.117700   \n",
       "565               -1.058611  ...      1.536720       2.047399   \n",
       "566               -0.895587  ...      0.561361       1.374854   \n",
       "567                1.043695  ...      1.961239       2.237926   \n",
       "568               -0.561032  ...     -1.410893       0.764190   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0           2.303601    2.001237          1.307686           2.616665   \n",
       "1           1.535126    1.890489         -0.375612          -0.430444   \n",
       "2           1.347475    1.456285          0.527407           1.082932   \n",
       "3          -0.249939   -0.550021          3.394275           3.893397   \n",
       "4           1.338539    1.220724          0.220556          -0.313395   \n",
       "..               ...         ...               ...                ...   \n",
       "564         1.752563    2.015301          0.378365          -0.273318   \n",
       "565         1.421940    1.494959         -0.691230          -0.394820   \n",
       "566         0.579001    0.427906         -0.809587           0.350735   \n",
       "567         2.303601    1.653171          1.430427           3.904848   \n",
       "568        -1.432735   -1.075813         -1.859019          -1.207552   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0           2.109526              2.296076        2.750622   \n",
       "1          -0.146749              1.087084       -0.243890   \n",
       "2           0.854974              1.955000        1.152255   \n",
       "3           1.989588              2.175786        6.046041   \n",
       "4           0.613179              0.729259       -0.868353   \n",
       "..               ...                   ...             ...   \n",
       "564         0.664512              1.629151       -1.360158   \n",
       "565         0.236573              0.733827       -0.531855   \n",
       "566         0.326767              0.414069       -1.104549   \n",
       "567         3.197605              2.289985        1.919083   \n",
       "568        -1.305831             -1.745063       -0.048138   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                   1.937015  \n",
       "1                   0.281190  \n",
       "2                   0.201391  \n",
       "3                   4.935010  \n",
       "4                  -0.397100  \n",
       "..                       ...  \n",
       "564                -0.709091  \n",
       "565                -0.973978  \n",
       "566                -0.318409  \n",
       "567                 2.219635  \n",
       "568                -0.751207  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     new_X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predcition = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "print('Score :',accuracy_score(y_test,model_predcition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 66,   1],\n",
       "       [  3, 118]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix is :')\n",
    "confusion_matrix(y_test,model_predcition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature = SelectKBest(chi2,k=30).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.66104917e+02, 9.38975081e+01, 2.01110286e+03, 5.39916559e+04,\n",
       "       1.49899264e-01, 5.40307549e+00, 1.97123536e+01, 1.05440354e+01,\n",
       "       2.57379775e-01, 7.43065536e-05, 3.46752472e+01, 9.79353970e-03,\n",
       "       2.50571896e+02, 8.75850471e+03, 3.26620664e-03, 6.13785332e-01,\n",
       "       1.04471761e+00, 3.05231563e-01, 8.03633831e-05, 6.37136566e-03,\n",
       "       4.91689157e+02, 1.74449400e+02, 3.66503542e+03, 1.12598432e+05,\n",
       "       3.97365694e-01, 1.93149220e+01, 3.95169151e+01, 1.34854195e+01,\n",
       "       1.29886140e+00, 2.31522407e-01])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feature.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst area                 112598.431564\n",
       "mean area                   53991.655924\n",
       "area error                   8758.504705\n",
       "worst perimeter              3665.035416\n",
       "mean perimeter               2011.102864\n",
       "worst radius                  491.689157\n",
       "mean radius                   266.104917\n",
       "perimeter error               250.571896\n",
       "worst texture                 174.449400\n",
       "mean texture                   93.897508\n",
       "worst concavity                39.516915\n",
       "radius error                   34.675247\n",
       "mean concavity                 19.712354\n",
       "worst compactness              19.314922\n",
       "worst concave points           13.485419\n",
       "mean concave points            10.544035\n",
       "mean compactness                5.403075\n",
       "worst symmetry                  1.298861\n",
       "concavity error                 1.044718\n",
       "compactness error               0.613785\n",
       "worst smoothness                0.397366\n",
       "concave points error            0.305232\n",
       "mean symmetry                   0.257380\n",
       "worst fractal dimension         0.231522\n",
       "mean smoothness                 0.149899\n",
       "dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_features = pd.Series(best_feature.scores_,index=X.columns).nlargest(25)\n",
    "ordered_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['worst area', 'mean area', 'area error', 'worst perimeter',\n",
       "       'mean perimeter', 'worst radius', 'mean radius', 'perimeter error',\n",
       "       'worst texture', 'mean texture', 'worst concavity', 'radius error',\n",
       "       'mean concavity', 'worst compactness', 'worst concave points',\n",
       "       'mean concave points', 'mean compactness', 'worst symmetry',\n",
       "       'concavity error', 'compactness error', 'worst smoothness',\n",
       "       'concave points error', 'mean symmetry', 'worst fractal dimension',\n",
       "       'mean smoothness'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_X[['worst area', 'mean area', 'area error', 'worst perimeter',\n",
    "       'mean perimeter', 'worst radius', 'mean radius', 'perimeter error',\n",
    "       'worst texture', 'mean texture', 'worst concavity', 'radius error',\n",
    "       'mean concavity', 'worst compactness', 'worst concave points','mean concave points', 'mean compactness', 'worst symmetry',\n",
    "       'concavity error', 'compactness error','worst smoothness',\n",
    "       'concave points error', 'mean symmetry', 'worst fractal dimension',\n",
    "       'mean smoothness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\.conda\\envs\\tensor\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_prediction = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score after feature selection is : 0.9840425531914894\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score after feature selection is :',accuracy_score(y_test,model1_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report is :\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        67\n",
      "           1       0.99      0.98      0.99       121\n",
      "\n",
      "    accuracy                           0.98       188\n",
      "   macro avg       0.98      0.98      0.98       188\n",
      "weighted avg       0.98      0.98      0.98       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report is :')\n",
    "print('\\n')\n",
    "print(classification_report(y_test,model1_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix after feature selection is\n",
      "\n",
      "\n",
      "[[ 66   1]\n",
      " [  2 119]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix after feature selection is')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,model1_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Accuracy increased after performing normalization(standard scaling) and feature selection\n",
    "2. Type 1 error and Type 2 error also get reduced after feature selection "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
